# ========= Data (CSV) =========
data_manager:
  # === TRAINING ===
  csv_path: "data/raw_data/mushroom_raw_data.csv"

  # === INFERENCE ===
  prod_database_path: "data/prod_data/database_prod.csv"              # auto-created
  real_time_data_prod_path: "data/prod_data/real_time_data_prod.csv"  # your streaming feed (UI source)
  predictions_path: "data/prod_data/predictions.csv"                  # auto-created/appended

# ========= Pipeline Runner =========
pipeline_runner:
  # === TRAINING ===
  model_path: "models/final_gbr.pkl"

  # === INFERENCE ===
  batch_size: 24                          # last N rows to build features
  time_increment: "1h"
  num_inference_steps: 5

# ========= Inference output formatting =========
inference:
  # Classification-friendly settings
  output_type: "label"        # "label" | "probability"
  positive_class: "POISONOUS" # used only if output_type == "probability"
  threshold: 0.5              # if you later want to turn probability into a boolean

# ========= Preprocessing =========
preprocessing:
  drop_columns:
    - veil-type   # only one category
    - stalk-root  # many missing values
    - datetime  # only used to differ between new incoming data from api

# ========= Training =========
training:
  target:
    source_col: poisonous   # column in the CSV with EDIBLE/POISONOUS
    horizon: 0              # ðŸ‘ˆ classification: no time shift, same-row label
    target_name: target
  train_fraction: 0.8

  # Used now by GradientBoostingClassifier (same params as regressor)
  gbr_params:
    n_estimators: 400
    learning_rate: 0.08
    max_depth: 3
    min_samples_leaf: 3
    subsample: 0.8
    max_features: "sqrt"
    random_state: 42

  grid_search:
    enabled: true
    param_grid:
      n_estimators: [200, 400]
      learning_rate: [0.05, 0.08, 0.1]
      max_depth: [2, 3]
      min_samples_leaf: [3, 5]
      subsample: [0.8, 1.0]
      max_features: ["sqrt", null]

# ========= Reports =========
reports:
  metrics_path: "reports/train_metrics.json"
